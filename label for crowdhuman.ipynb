{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afde3d44-6e0a-4b21-b208-6e3bc3d3f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79a13be7-dddf-4ef1-a3b8-65d994f75d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from argparse import ArgumentParser\n",
    "import requests\n",
    "import os, cv2\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12df62d8-7e7f-41d5-9160-bb45d17f924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = \"./annotation_val.odgt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5c6eec-658c-42ca-97b6-6903287f2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class= [\"vbody\"]\n",
    "crowdHuman_path = \"val/\"\n",
    "datasetPath = \"yolo_crowd_dataset/\"\n",
    "imgPath = \"images/\"\n",
    "labelPath = \"labels/\"\n",
    "imgType = \".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a7a3489-9ec2-4253-ab82-105a26e162c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateYOLO(filename, bbox):\n",
    "    file = open(os.path.join(datasetPath, labelPath, filename+'.txt'), \"w\")\n",
    "    file.writelines(bbox)\n",
    "    file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "235ab1c4-7d2a-4702-b184-9a0265d4fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(size, box, img_id):\n",
    "    if box[0] > size[0] or box[2] > size[0] or box[1] > size[1] or box[3] > size[1]:  \n",
    "        ###wrong labelling, label coordinate is bigger than or overside the image size\n",
    "        w = open(os.path.join(datasetPath, 'tagging_box_error'), 'a')\n",
    "        w.write(img_id+'\\n')\n",
    "        w.close\n",
    "        return [''] ###return nothing, give up this label\n",
    "    dw = 1./(size[0])\n",
    "    dh = 1./(size[1])\n",
    "    xmax = abs(box[0]) + abs(box[2])\n",
    "    ymax = abs(box[1]) + abs(box[3])\n",
    "    if xmax > size[0]:  ###avoid the label box out of the image\n",
    "        xmax = size[0]\n",
    "    if ymax > size[1]:\n",
    "        ymax = size[1]\n",
    "    x = (abs(box[0]) + xmax)/2.0 - 1\n",
    "    y = (abs(box[1]) + ymax)/2.0 - 1\n",
    "    w = abs(box[2])\n",
    "    h = abs(box[3])\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return [str(0), ' ', str(round(x, 6)),' ', str(round(y, 6)), ' ', str(round(w, 6)), ' ', str(round(h, 6)), '\\n'] \n",
    "    ###the first one, index 0, is the class id and assuem \"person\" class is 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e90370b-e26d-4f25-b9d8-bef53257273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(annotations_path)\n",
    "lines = f.readlines()\n",
    "total_lines = len(lines)\n",
    "\n",
    "for lineID, line in enumerate(lines):\n",
    "    data = eval(line)\n",
    "    img_id = data[\"ID\"]\n",
    "    \n",
    "    image_path = os.path.join(crowdHuman_path, img_id+'.jpg')\n",
    "    if os.path.exists(image_path):\n",
    "        img = cv2.imread(image_path)\n",
    "        #cv2.imwrite(os.path.join(datasetPath, imgPath, img_id + imgType), img) ###uncomment to generate image\n",
    "        (img_height, img_width, img_depth) = img.shape\n",
    "        total_iid = len(data[\"gtboxes\"])       \n",
    "        box_list=[]\n",
    "\n",
    "        for iid, infoBody in enumerate(data[\"gtboxes\"]):\n",
    "            if infoBody['tag'] != 'mask':\n",
    "                tag = infoBody[\"tag\"]\n",
    "                hbox = infoBody[\"hbox\"]\n",
    "                head_attr = infoBody[\"head_attr\"]\n",
    "                fbox = infoBody[\"fbox\"]\n",
    "                vbox = infoBody[\"vbox\"]\n",
    "                extra = infoBody[\"extra\"]\n",
    "                difficult = 0\n",
    "\n",
    "                if(len(target_class)==0 or (\"head\" in target_class)):\n",
    "                    box_list.extend(convert((img_width, img_height), hbox, img_id))\n",
    "\n",
    "                if(len(target_class)==0 or (\"fbody\" in target_class)):\n",
    "                    box_list.extend(convert((img_width, img_height), fbox, img_id))\n",
    "\n",
    "                if(len(target_class)==0 or (\"vbody\" in target_class)):\n",
    "                    box_list.extend(convert((img_width, img_height), vbox, img_id))\n",
    "        \n",
    "                print(\"[Left over] {}/{} , {}: head:{} full:{} visible:{}\".format(total_lines-lineID, total_iid-iid, img_id,\\\n",
    "                    hbox, fbox, vbox)) #end of one label object loop \n",
    "        generateYOLO(img_id, box_list) #end of one image loop\n",
    "    else:\n",
    "        f = open(os.path.join(datasetPath, 'no_this_image_log'), 'a')  ###can't find the label file name in imgPath\n",
    "        f.write(img_id+'\\n')\n",
    "        f.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f947f-e092-440f-9311-74d931f052a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://chdataset/crowdhuman_dataset/images/val/ ./val --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dea6d2-6d1a-40e6-a0c4-f95196081663",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp /home/sagemaker-user/yolo_crowd_dataset/labels/ s3://chdataset/crowdhuman_dataset/labels/val/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab11b027-00a1-4f65-a25f-dd757f16d7d4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3, os, sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d4ecf-a805-4d20-87e9-97d398b9d983",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"yolo_crowd_dataset/labels/\"\n",
    "s3 = boto3.client('s3')\n",
    "sess = sagemaker.Session()\n",
    "smclient = boto3.Session().client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9de2d64-b2ba-4f73-930f-0ca477b27ad2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "path = \"yolo_crowd_dataset/labels/\"\n",
    "s3 = boto3.client('s3')\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "if os.path.exists(path):\n",
    "    file_lists = os.listdir(path)\n",
    "\n",
    "    for file in file_lists:\n",
    "        if file.endswith(\".txt\"):\n",
    "            sess.upload_data(path+file, bucket = 'chdataset',key_prefix = \"crowdhuman_dataset/labels/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc7cc1e-5c0e-4202-bccb-33bc8ede55f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://chdataset/crowdhuman_dataset/images/Images.zip to ./Images.zip\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://chdataset/crowdhuman_dataset/images/Images.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c143445e-ded2-41e9-98cd-6ddffac11f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip Images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0054bea-afe8-4773-a87e-f1dd38167db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "path = \"Images/\"\n",
    "s3 = boto3.client('s3')\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "if os.path.exists(path):\n",
    "    file_lists = os.listdir(path)\n",
    "    for file in file_lists:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            sess.upload_data(path+file, bucket = 'chdataset',key_prefix = \"crowdhuman_dataset/images/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4b30385-ef02-4ae5-b191-2422ed2a13c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = \"./annotation_train.odgt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b92611cf-c42f-4e63-883c-50626a2987bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class= [\"vbody\"]\n",
    "crowdHuman_path = \"Images/\"\n",
    "datasetPath = \"yolo_crowd_dataset/\"\n",
    "imgPath = \"images/\"\n",
    "labelPath = \"labels/\"\n",
    "trainlabelPath = \"train_labels/\"\n",
    "imgType = \".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9adab704-cb74-4ce5-b4ec-555fd96f0b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateYOLO(filename, bbox):\n",
    "    file = open(os.path.join(datasetPath, trainlabelPath, filename+'.txt'), \"w\")\n",
    "    file.writelines(bbox)\n",
    "    file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9db8d276-2752-46bc-98f7-6bfe2a2a9a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(size, box, img_id):\n",
    "    if box[0] > size[0] or box[2] > size[0] or box[1] > size[1] or box[3] > size[1]:  \n",
    "        ###wrong labelling, label coordinate is bigger than or overside the image size\n",
    "        w = open(os.path.join(datasetPath, 'tagging_box_error'), 'a')\n",
    "        w.write(img_id+'\\n')\n",
    "        w.close\n",
    "        return [''] ###return nothing, give up this label\n",
    "    dw = 1./(size[0])\n",
    "    dh = 1./(size[1])\n",
    "    xmax = abs(box[0]) + abs(box[2])\n",
    "    ymax = abs(box[1]) + abs(box[3])\n",
    "    if xmax > size[0]:  ###avoid the label box out of the image\n",
    "        xmax = size[0]\n",
    "    if ymax > size[1]:\n",
    "        ymax = size[1]\n",
    "    x = (abs(box[0]) + xmax)/2.0 - 1\n",
    "    y = (abs(box[1]) + ymax)/2.0 - 1\n",
    "    w = abs(box[2])\n",
    "    h = abs(box[3])\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return [str(0), ' ', str(round(x, 6)),' ', str(round(y, 6)), ' ', str(round(w, 6)), ' ', str(round(h, 6)), '\\n'] \n",
    "    ###the first one, index 0, is the class id and assuem \"person\" class is 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db8283-723b-4085-9046-3c5fdaa3b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(annotations_path)\n",
    "lines = f.readlines()\n",
    "total_lines = len(lines)\n",
    "\n",
    "for lineID, line in enumerate(lines):\n",
    "    data = eval(line)\n",
    "    img_id = data[\"ID\"]\n",
    "    \n",
    "    image_path = os.path.join(crowdHuman_path, img_id+'.jpg')\n",
    "    if os.path.exists(image_path):\n",
    "        img = cv2.imread(image_path)\n",
    "        #cv2.imwrite(os.path.join(datasetPath, imgPath, img_id + imgType), img) ###uncomment to generate image\n",
    "        (img_height, img_width, img_depth) = img.shape\n",
    "        total_iid = len(data[\"gtboxes\"])       \n",
    "        box_list=[]\n",
    "\n",
    "        for iid, infoBody in enumerate(data[\"gtboxes\"]):\n",
    "            if infoBody['tag'] != 'mask':\n",
    "                tag = infoBody[\"tag\"]\n",
    "                hbox = infoBody[\"hbox\"]\n",
    "                head_attr = infoBody[\"head_attr\"]\n",
    "                fbox = infoBody[\"fbox\"]\n",
    "                vbox = infoBody[\"vbox\"]\n",
    "                extra = infoBody[\"extra\"]\n",
    "                difficult = 0\n",
    "\n",
    "                if(len(target_class)==0 or (\"head\" in target_class)):\n",
    "                    box_list.extend(convert((img_width, img_height), hbox, img_id))\n",
    "\n",
    "                if(len(target_class)==0 or (\"fbody\" in target_class)):\n",
    "                    box_list.extend(convert((img_width, img_height), fbox, img_id))\n",
    "\n",
    "                if(len(target_class)==0 or (\"vbody\" in target_class)):\n",
    "                    box_list.extend(convert((img_width, img_height), vbox, img_id))\n",
    "        \n",
    "                print(\"[Left over] {}/{} , {}: head:{} full:{} visible:{}\".format(total_lines-lineID, total_iid-iid, img_id,\\\n",
    "                    hbox, fbox, vbox)) #end of one label object loop \n",
    "        generateYOLO(img_id, box_list) #end of one image loop\n",
    "    else:\n",
    "        f = open(os.path.join(datasetPath, 'no_this_image_log'), 'a')  ###can't find the label file name in imgPath\n",
    "        f.write(img_id+'\\n')\n",
    "        f.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d686264-264c-44fd-8bd9-6a4cc90b4d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo_crowd_dataset/train_labels/\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "image_path = os.path.join(datasetPath, trainlabelPath)\n",
    "print(image_path)\n",
    "num_files = len([f for f in os.listdir(image_path)])\n",
    "print(num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b7885af-4dbe-49d0-9690-fb476385b9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "path = \"yolo_crowd_dataset/train_labels/\"\n",
    "s3 = boto3.client('s3')\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "if os.path.exists(path):\n",
    "    file_lists = os.listdir(path)\n",
    "\n",
    "    for file in file_lists:\n",
    "        if file.endswith(\".txt\"):\n",
    "            sess.upload_data(path+file, bucket = 'chdataset',key_prefix = \"crowdhuman_dataset/labels/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "071a7026-34c8-49d6-a71b-9327adec1047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d6225f-0db8-438c-b4a4-7dd02f85382b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
